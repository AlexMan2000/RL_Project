{
    "layers": [
        {
            "size": 128,
            "activation": "relu",
            "dropout_rate": 0.1,
            "batch_norm": true,
            "layer_norm": false
        },
        {
            "size": 256,
            "activation": "leaky_relu",
            "dropout_rate": 0.3,
            "batch_norm": true,
            "layer_norm": false
        },
        {
            "size": 256,
            "activation": "gelu",
            "dropout_rate": 0.15,
            "batch_norm": false,
            "layer_norm": true
        },
        {
            "size": 128,
            "activation": "relu",
            "dropout_rate": 0.1,
            "batch_norm": true,
            "layer_norm": false
        }
    ],
    "initialization": "kaiming"
} 